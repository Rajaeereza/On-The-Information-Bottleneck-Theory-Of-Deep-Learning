{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfoYbgh5Mdnh",
        "outputId": "2ca8de87-3fe8-4a34-9b34-66973f9885c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create a folder in the root directory\n",
        "!mkdir -p \"/content/drive/My Drive/My Folder_kde\""
      ],
      "metadata": {
        "id": "AnWxLUU5MmrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader\n",
        "import time as time\n",
        "import numpy as np\n",
        "from IPython import display"
      ],
      "metadata": {
        "id": "IyvLGQSSUjkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MNIST(root=\"./\", train=False, download=True, transform=ToTensor())\n",
        "image, label = dataset.__getitem__(0)\n",
        "plt.imshow(image.squeeze(0),cmap=\"binary\")\n",
        "plt.show()\n",
        "print(\"Image size\", image.shape)\n",
        "print(\"Label\", label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "XkLrJNloUr9v",
        "outputId": "198d298d-d0c9-41c3-d5c9-4044445be232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 190276113.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 30520457.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 71804179.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 19823651.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size torch.Size([1, 28, 28])\n",
            "Label 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 100\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=os.cpu_count())"
      ],
      "metadata": {
        "id": "xi25Nm7JYgCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_whole = DataLoader(dataset, batch_size=10000, shuffle=False, num_workers=os.cpu_count())\n",
        "NUM_LABELS = 10\n",
        "labelixs = {}\n",
        "for _,label in dataloader_whole:\n",
        "\n",
        "  for i in range(NUM_LABELS):\n",
        "    labelixs[i] = label == i\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_Ktof2f6bePB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wjKOr2SX7NA",
        "outputId": "66d9fa14-ad76-4b05-9cfd-8aa3cc4e3e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: ./\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class cnnblock(nn.Module):\n",
        "\n",
        "  def __init__(self, input_cha, output_cha, size, activation = \"tanh\", stride = 2, padding=1):\n",
        "    super().__init__()\n",
        "\n",
        "    if activation==\"tanh\":\n",
        "      self.model = nn.Sequential(\n",
        "          nn.Conv2d(input_cha, output_cha, size, bias=False, stride=stride, padding=1),\n",
        "          nn.BatchNorm2d((output_cha)),\n",
        "          nn.Tanh()\n",
        "      )\n",
        "    else:\n",
        "      self.model = nn.Sequential(\n",
        "          nn.Conv2d(input_cha, output_cha, size, bias=False, stride=stride, padding=1),\n",
        "          nn.BatchNorm2d((output_cha)),\n",
        "          nn.ReLU()\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "        y = self.model(x)\n",
        "        return y\n",
        "\n",
        "\n",
        "class cnn(nn.Module):\n",
        "\n",
        "   def __init__(self, activation):\n",
        "    super().__init__()\n",
        "    self.p = nn.ZeroPad2d(2)\n",
        "    self.l1 = cnnblock(1, 4, 2, activation, stride = 1)\n",
        "    self.l2 = cnnblock(4, 6, 2, activation, stride = 1)\n",
        "    self.l3 = cnnblock(6, 12, 1, activation)\n",
        "    self.l4 = cnnblock(12, 24, 1, activation)\n",
        "    self.av = nn.AvgPool2d((3,3))\n",
        "    self.flat = nn.Flatten()\n",
        "    self.lin = nn.Linear(in_features=216, out_features=10)\n",
        "    self.sig = nn.Sigmoid()\n",
        "   def forward(self,input):\n",
        "    input = self.p(input)\n",
        "    l1 = self.l1(input)\n",
        "    l2 = self.l2(l1)\n",
        "    l3 = self.l3(l2)\n",
        "    l4 = self.l4(l3)\n",
        "    av = self.av(l4)\n",
        "    flat = self.flat(av)\n",
        "    lin = self.lin(flat)\n",
        "    sig = self.sig(lin)\n",
        "    return sig,l1,l2,l3,l4"
      ],
      "metadata": {
        "id": "cfYp4Exlcj46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHa96eYAZYnD"
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        # nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "    if classname.find('Linear') != -1:\n",
        "        #nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.2)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_tanh = cnn(\"tanh\").to(device)\n",
        "cnn_tanh.apply(weights_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCmViunfY4dM",
        "outputId": "8dd7c5d5-eb4f-44d6-98cb-091d4c44a7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cnn(\n",
              "  (p): ZeroPad2d((2, 2, 2, 2))\n",
              "  (l1): cnnblock(\n",
              "    (model): Sequential(\n",
              "      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l2): cnnblock(\n",
              "    (model): Sequential(\n",
              "      (0): Conv2d(4, 6, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l3): cnnblock(\n",
              "    (model): Sequential(\n",
              "      (0): Conv2d(6, 12, kernel_size=(1, 1), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l4): cnnblock(\n",
              "    (model): Sequential(\n",
              "      (0): Conv2d(12, 24, kernel_size=(1, 1), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (av): AvgPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0)\n",
              "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
              "  (lin): Linear(in_features=216, out_features=10, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(cnn_tanh,input_size = (1, 28, 28), batch_size = 100,device = device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCy3v9Q1iToW",
        "outputId": "a208a970-9564-4290-d240-33acb43418b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "         ZeroPad2d-1           [100, 1, 32, 32]               0\n",
            "            Conv2d-2           [100, 4, 33, 33]              16\n",
            "       BatchNorm2d-3           [100, 4, 33, 33]               8\n",
            "              Tanh-4           [100, 4, 33, 33]               0\n",
            "          cnnblock-5           [100, 4, 33, 33]               0\n",
            "            Conv2d-6           [100, 6, 34, 34]              96\n",
            "       BatchNorm2d-7           [100, 6, 34, 34]              12\n",
            "              Tanh-8           [100, 6, 34, 34]               0\n",
            "          cnnblock-9           [100, 6, 34, 34]               0\n",
            "           Conv2d-10          [100, 12, 18, 18]              72\n",
            "      BatchNorm2d-11          [100, 12, 18, 18]              24\n",
            "             Tanh-12          [100, 12, 18, 18]               0\n",
            "         cnnblock-13          [100, 12, 18, 18]               0\n",
            "           Conv2d-14          [100, 24, 10, 10]             288\n",
            "      BatchNorm2d-15          [100, 24, 10, 10]              48\n",
            "             Tanh-16          [100, 24, 10, 10]               0\n",
            "         cnnblock-17          [100, 24, 10, 10]               0\n",
            "        AvgPool2d-18            [100, 24, 3, 3]               0\n",
            "          Flatten-19                 [100, 216]               0\n",
            "           Linear-20                  [100, 10]           2,170\n",
            "          Sigmoid-21                  [100, 10]               0\n",
            "================================================================\n",
            "Total params: 2,734\n",
            "Trainable params: 2,734\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.30\n",
            "Forward/backward pass size (MB): 54.78\n",
            "Params size (MB): 0.01\n",
            "Estimated Total Size (MB): 55.09\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ONizSqF6ZIv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt= torch.optim.SGD(cnn_tanh.parameters(), lr=0.01, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "NCJiyUUpeGNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(images, label, cnn, BATCH_SIZE, opt):\n",
        "\n",
        "    prob,l1_out,l2_out,l3_out,l4_out = cnn(images)\n",
        "    cnn_loss = loss(prob, label.to(device))\n",
        "    opt.zero_grad()\n",
        "    cnn_loss.backward()\n",
        "    opt.step()\n",
        "    return cnn_loss, prob,l1_out,l2_out,l3_out,l4_out\n"
      ],
      "metadata": {
        "id": "OsOXtMGGeORx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "21DesYcnndjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.special as sp\n",
        "\n",
        "\n",
        "def get_dists(X):\n",
        "    \"\"\"code to compute the pairwise distance matrix for a set of\n",
        "    vectors specifie by the matrix X.\n",
        "    \"\"\"\n",
        "    x2 = (X**2).sum(axis=1)[:,None]\n",
        "    dists = x2 + x2.T - 2*X.dot(X.T)\n",
        "    return dists\n",
        "\n",
        "def get_shape(x):\n",
        "    dims = float(x.shape[1])\n",
        "    N    = float(x.shape[0])\n",
        "    return dims, N\n",
        "\n",
        "def entropy_estimator_kl(x, var):\n",
        "    # KL-based upper bound on entropy of mixture of Gaussians with covariance matrix var * I\n",
        "    #  see Kolchinsky and Tracey, Estimating Mixture Entropy with Pairwise Distances, Entropy, 2017. Section 4.\n",
        "    #  and Kolchinsky and Tracey, Nonlinear Information Bottleneck, 2017. Eq. 10\n",
        "    dims, N = get_shape(x)\n",
        "    dists = get_dists(x)\n",
        "    dists2 = dists / (2*var)\n",
        "    normconst = (dims / 2.0)*np.log(2*np.pi*var)\n",
        "    lprobs = sp.logsumexp(-dists2, axis=1) - np.log(N) - normconst\n",
        "    h = -np.mean(lprobs)\n",
        "    return dims/2 + h\n",
        "\n",
        "def entropy_estimator_bd(x, var):\n",
        "    # Bhattacharyya-based lower bound on entropy of mixture of Gaussians with covariance matrix var * I\n",
        "    #  see Kolchinsky and Tracey, Estimating Mixture Entropy with Pairwise Distances, Entropy, 2017. Section 4.\n",
        "    dims, N = get_shape(x)\n",
        "    val = entropy_estimator_kl(x, 4*var)\n",
        "    return val + np.log(0.25)*dims / 2\n",
        "\n",
        "def kde_condentropy(output, var):\n",
        "    # Return entropy of a multivariate Gaussian, in nats\n",
        "    dims = output.shape[1]\n",
        "    return (dims / 2.0) * (np.log(2 * np.pi * var) + 1)"
      ],
      "metadata": {
        "id": "a2IzYivbGjzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mi_data = {0: {\"x_u\":[],\"y_u\":[],\"x_l\":[],\"y_l\":[],\"h_l\":[],\"h_u\":[]}, 1: {\"x_u\":[],\"y_u\":[],\"x_l\":[],\"y_l\":[],\"h_l\":[],\"h_u\":[]},\n",
        "           2: {\"x_u\":[],\"y_u\":[],\"x_l\":[],\"y_l\":[],\"h_l\":[],\"h_u\":[]}, 3: {\"x_u\":[],\"y_u\":[],\"x_l\":[],\"y_l\":[],\"h_l\":[],\"h_u\":[]}}\n",
        "\n",
        "activities = [np.zeros((10000, 4, 33,33)),\n",
        "              np.zeros((10000, 6, 34,34)),\n",
        "              np.zeros((10000 ,12, 18,18)),\n",
        "              np.zeros((10000 ,24, 10,10))]\n",
        "\n",
        "for layer_no in range(4):\n",
        "    mi_data[layer_no]['full'] = []\n",
        "    for f in range(activities[layer_no].shape[1]):\n",
        "        mi_data[layer_no][f'F{f + 1}'] = []\n",
        "\n",
        "def train(dataloader, epochs, cnn, BATCH_SIZE, opt):\n",
        "  loss_list = []\n",
        "  acc_list = []\n",
        "  for epoch in range(epochs):\n",
        "    losses = []\n",
        "    conc_out = []\n",
        "    conc_label = []\n",
        "    i=0\n",
        "    print(epoch)\n",
        "    for image_batch, label in dataloader:\n",
        "        image_batch = image_batch.to(device)\n",
        "        cnn_loss, prob,l1_out,l2_out,l3_out,l4_out = train_step(image_batch,label, cnn, BATCH_SIZE, opt)\n",
        "        for num in range(100):\n",
        "            activities[0][num+i]=l1_out[num].detach().cpu().numpy()\n",
        "            activities[1][num+i]=l2_out[num].detach().cpu().numpy()\n",
        "            activities[2][num+i]=l3_out[num].detach().cpu().numpy()\n",
        "            activities[3][num+i]=l4_out[num].detach().cpu().numpy()\n",
        "\n",
        "        i+=100\n",
        "        losses.append(cnn_loss.detach().cpu().item())\n",
        "        conc_out.append(prob.detach().cpu())\n",
        "        conc_label.append(label.detach().cpu())\n",
        "\n",
        "    for idx, layer in enumerate(activities):\n",
        "        layer_full = np.array([layer[fn].flatten() for fn in range(len(layer))])\n",
        "        H_up = entropy_estimator_kl(layer_full, 1e-1)\n",
        "        H_lo = entropy_estimator_bd(layer_full, 1e-1)\n",
        "\n",
        "        H_T_X = kde_condentropy(layer_full, 1e-1)\n",
        "\n",
        "        H_Y_T_up = 0\n",
        "        H_Y_T_lo = 0\n",
        "        for label, ixs in labelixs.items():\n",
        "          b = ixs.long()\n",
        "          b = np.array(b)\n",
        "          H_Y_T_up += b.mean() * entropy_estimator_kl(layer_full[ixs, :], 1e-1)\n",
        "          H_Y_T_lo += b.mean() * entropy_estimator_bd(layer_full[ixs, :], 1e-1)\n",
        "\n",
        "        mi_data[idx]['x_u'].append((1.0/np.log(2)) * (H_up - H_T_X))\n",
        "        mi_data[idx]['y_u'].append((1.0/np.log(2)) * (H_up - H_Y_T_up))\n",
        "\n",
        "        mi_data[idx]['x_l'].append((1.0/np.log(2)) * (H_lo - H_T_X))\n",
        "        mi_data[idx]['y_l'].append((1.0/np.log(2)) * (H_lo - H_Y_T_lo))\n",
        "\n",
        "        mi_data[idx]['h_u'].append((1.0/np.log(2))* H_up / layer_full.shape[1] )\n",
        "        mi_data[idx]['h_l'].append((1.0/np.log(2))* H_lo / layer_full.shape[1] )\n",
        "\n",
        "\n",
        "    conc_out = torch.cat(conc_out)\n",
        "    conc_label = torch.cat(conc_label)\n",
        "    acc = accuracy_score(conc_label, conc_out.argmax(axis=1))\n",
        "    loss_list.append(np.mean(losses))\n",
        "    acc_list.append(acc)\n",
        "  return loss_list , acc_list"
      ],
      "metadata": {
        "id": "7AJ5VOcDggvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=250\n",
        "loss_list, acc_list = train(dataloader,epochs, cnn_tanh, BATCH_SIZE, opt)"
      ],
      "metadata": {
        "id": "y6GOU8nBhZj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2ae8ee-a603-48e6-995f-9c1ffad9e057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n"
          ]
        }
      ]
    }
  ]
}